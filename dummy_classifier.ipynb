{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ITMAL Exercise\n",
    "\n",
    "## Implementing a dummy binary-classifier with fit-predict interface\n",
    "\n",
    "We begin with the MNIST data-set and will reuse the data loader from Scikit-learn. Next we create a dummy classifier, and compare the results of the SGD and dummy classifiers using the MNIST data...\n",
    "\n",
    "#### Qa  Load and display the MNIST data\n",
    "\n",
    "There is a `sklearn.datasets.fetch_openml` dataloader interface in Scikit-learn. You can load MNIST data like \n",
    "\n",
    "```python\n",
    "from sklearn.datasets import fetch_openml\n",
    "# Load data from https://www.openml.org/d/554\n",
    "X, y = fetch_openml('mnist_784',??) # needs to return X, y, replace '??' with suitable parameters! \n",
    "# Convert to [0;1] via scaling (not always needed)\n",
    "#X = X / 255.\n",
    "```\n",
    "\n",
    "but you need to set parameters like `return_X_y` and `cache` if the default values are not suitable! \n",
    "\n",
    "Check out the documentation for the `fetch_openml` MNIST loader, try it out by loading a (X,y) MNIST data set, and plot a single digit via the `MNIST_PlotDigit` function here (input data is a 28x28 NMIST subimage)\n",
    "\n",
    "```python\n",
    "%matplotlib inline\n",
    "def MNIST_PlotDigit(data):\n",
    "    import matplotlib\n",
    "    import matplotlib.pyplot as plt\n",
    "    image = data.reshape(28, 28)\n",
    "    plt.imshow(image, cmap = matplotlib.cm.binary, interpolation=\"nearest\")\n",
    "    plt.axis(\"off\")\n",
    "```\n",
    "\n",
    "Finally, put the MNIST loader into a single function called `MNIST_GetDataSet()` so you can resuse it later."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: add your code here..\n",
    "from sklearn.datasets import fetch_openml\n",
    "X, y = fetch_openml('mnist_784', return_X_y=True)\n",
    "X=X/255\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "def MNIST_PlotDigit(data):\n",
    "    import matplotlib\n",
    "    import matplotlib.pyplot as plt\n",
    "    image = data.reshape(28, 28)\n",
    "    plt.imshow(image, cmap = matplotlib.cm.binary, interpolation=\"nearest\")\n",
    "    plt.axis(\"off\")\n",
    "MNIST_PlotDigit(X[0])\n",
    "five_digit = X[0]\n",
    "print(y[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def MNIST_GetDataSet():\n",
    "    X, y = fetch_openml('mnist_784', return_X_y=True)\n",
    "    X=X/255\n",
    "    return X,y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Qb  Add a Stochastic Gradient Decent [SGD] Classifier\n",
    "\n",
    "Create a train-test data-set for MNIST and then add the `SGDClassifier` as done in [HOML], p.88.\n",
    "\n",
    "Split your data and run the fit-predict for the classifier using the MNIST data.(We will be looking at cross-validation instead of the simple fit-predict in a later exercise.)\n",
    "\n",
    "Notice that you have to reshape the MNIST X-data to be able to use the classifier. It may be a 3D array, consisting of 70000 (28 x 28) images, or just a 2D array consisting of 70000 elements of size 784.\n",
    "\n",
    "A simple `reshape()` could fix this on-the-fly:\n",
    "```python\n",
    "X, y = MNIST_GetDataSet()\n",
    "\n",
    "print(f\"X.shape={X.shape}\") # print X.shape= (70000, 28, 28)\n",
    "if X.ndim==3:\n",
    "    print(\"reshaping X..\")\n",
    "    assert y.ndim==1\n",
    "    X = X.reshape((X.shape[0],X.shape[1]*X.shape[2]))\n",
    "assert X.ndim==2\n",
    "print(f\"X.shape={X.shape}\") # X.shape= (70000, 784)\n",
    "```\n",
    "\n",
    "Remember to use the category-5 y inputs\n",
    "\n",
    "```python\n",
    "y_train_5 = (y_train == '5')    \n",
    "y_test_5  = (y_test == '5')\n",
    "```\n",
    "instead of the `y`'s you are getting out of the dataloader. In effect, we have now created a binary-classifier, that enable us to classify a particular data sample, $\\mathbf{x}(i)$ (that is a 28x28 image), as being a-class-5 or not-a-class-5. \n",
    "\n",
    "Test your model on using the test data, and try to plot numbers that have been categorized correctly. Then also find and plots some misclassified numbers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X.shape=(70000, 784)\n",
      "X.shape=(70000, 784)\n"
     ]
    }
   ],
   "source": [
    "# TODO: add your code here.. qB\n",
    "import numpy as np\n",
    "X, y = MNIST_GetDataSet()\n",
    "\n",
    "print(f\"X.shape={X.shape}\") # print X.shape= (70000, 28, 28)\n",
    "if X.ndim==3:\n",
    "    print(\"reshaping X..\")\n",
    "    assert y.ndim==1\n",
    "    X = X.reshape((X.shape[0],X.shape[1]*X.shape[2]))\n",
    "assert X.ndim==2\n",
    "print(f\"X.shape={X.shape}\") # X.shape= (70000, 784)\n",
    "\n",
    "# rescale the data, use the traditional train/test split\n",
    "X_train, X_test, y_train, y_test = X[:60000], X[60000:], y[:60000], y[60000:]\n",
    "y_train = y_train.astype(np.int8)\n",
    "shuffle_index = np.random.permutation(60000)\n",
    "X_train, y_train = X_train[shuffle_index], y_train[shuffle_index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_5 = (y_train == 5) # True for all 5s, False for all other digits.\n",
    "y_test_5 = (y_test == 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SGDClassifier(random_state=42)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import SGDClassifier\n",
    "sgd_clf = SGDClassifier(random_state=42)\n",
    "## Fitting the linear model with Stochastic Gradient Descent against the target digit \"5\"\n",
    "sgd_clf.fit(X_train, y_train_5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ True])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Taking the five from earlier and testing if the model can predict it \n",
    "sgd_clf.predict([five_digit])\n",
    "## it did! "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([False])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "MNIST_PlotDigit(X[1])\n",
    "zero_digit=X[1]\n",
    "sgd_clf.predict([zero_digit])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n"
     ]
    }
   ],
   "source": [
    "print(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SGD classified the sample as being  [False]  meaning not five\n",
      "But it was really a five \n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "for i in range(len(X_train)):\n",
    "    if(sgd_clf.predict([X_train[i]])!=y_train_5[i]):\n",
    "        print('SGD classified the sample as being ', sgd_clf.predict([X[i]]) , ' meaning not five')\n",
    "        print('But it was really a five ')\n",
    "        MNIST_PlotDigit(X_train[i])\n",
    "        break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Qc Implement a dummy binary classifier\n",
    "\n",
    "Now we will try to create a Scikit-learn compatible estimator implemented via a python class. Follow the code found in [HOML], p.90, but name you estimator `DummyClassifier` instead of `Never5Classifyer`.\n",
    "\n",
    "Here our Python class knowledge comes into play. The estimator class hierarchy looks like\n",
    "\n",
    "<img src=\"https://blackboard.au.dk/bbcswebdav/courses/BB-Cou-UUVA-94506/Fildeling/L02/Figs/class_base_estimator.png\" alt=\"WARNING: you need to be logged into Blackboard to view images\" style=\"width:500px\">\n",
    "\n",
    "All Scikit-learn classifiers inherit from `BaseEstimator` (and possibly also `ClassifierMixin`), and they must have a `fit-predict` function pair (strangely not in the base class!) and you can actually find the `sklearn.base.BaseEstimator` and `sklearn.base.ClassifierMixin` python source code somewhere in you anaconda install dir, if you should have the nerves to go to such interesting details.\n",
    "\n",
    "But surprisingly you may just want to implement a class that contains the `fit-predict` functions, ___without inheriting___ from the `BaseEstimator`, things still work due to the pythonic 'duck-typing': you just need to have the class implement the needed interfaces, obviously `fit()` and `predict()` but also the more obscure `get_params()` etc....then the class 'looks like' a `BaseEstimator`...and if it looks like an estimator, it _is_ an estimator (aka. duck typing).\n",
    "\n",
    "Templates in C++ also allow the language to use compile-time duck typing!\n",
    "\n",
    "> https://en.wikipedia.org/wiki/Duck_typing\n",
    "\n",
    "Call the fit-predict on a newly instantiated `DummyClassifier` object, and find a way to extract the accuracy `score` from the test data. You may implement an accuracy function yourself or just use the `sklearn.metrics.accuracy_score` function. \n",
    "\n",
    "Finally, compare the accuracy score from your `DummyClassifier` with the scores found in [HOML] \"Measuring Accuracy Using Cross-Validation\", p.89. Are they comparable? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: add your code here..\n",
    "from sklearn.base import BaseEstimator\n",
    "from sklearn.metrics import accuracy_score\n",
    "## Dummy classifier --> classfies every input as not-5\n",
    "## only \"wrong\" when input is a 5. \n",
    "class DummyClassifier(BaseEstimator):\n",
    "    def fit(self, X, y=None):\n",
    "        pass\n",
    "    def predict(self, X):\n",
    "        return np.zeros((len(X), 1), dtype=bool)\n",
    "DummyClassifierobj = DummyClassifier()\n",
    "DummyClassifierobj.fit(X_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.90965"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(y_train_5, DummyClassifierobj.predict(X_train))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Qd Conclusion\n",
    "\n",
    "Now, conclude on all the exercise above. \n",
    "\n",
    "Write a short textual conclusion (max. 10- to 20-lines) that extract the _essence_ of the exercises: why did you think it was important to look at these particular ML concepts, and what was our overall learning outcome of the exercises (in broad terms)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Qd concluding remarks in text.."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "REVISIONS||\n",
    "---------||\n",
    "2018-1219| CEF, initial.                  \n",
    "2018-0206| CEF, updated and spell checked. \n",
    "2018-0208| CEF, minor text update.\n",
    "2018-0305| CEF, updated with SHN comments.\n",
    "2019-0902| CEF, updated for ITMAL v2.\n",
    "2019-0904| CEF, updated and added conclusion Q.\n",
    "2020-0125| CEF, F20 ITMAL update.\n",
    "2020-0204| CEF, updated page numbers to HOMLv2.\n",
    "2020-0903| CEF, E20 ITMAL update, udpated figs paths.\n",
    "2020-0906| CEF, added alt text.\n",
    "2020-0918| CEF, added binary-classifier text to Qb to emphasise 5/non-5 classification.\n",
    "2021-0112| CEF, F21 ITMAL update, moved revision tabel.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "position": {
    "height": "144.517px",
    "left": "1230px",
    "right": "20px",
    "top": "119px",
    "width": "350px"
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
